{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Handwritten Digits from the MNIST Database\n",
    "\n",
    "We will illustrate multiple Machine Learning algorithms by using them for classifying handwritten digits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Classwise Logistic Regression\n",
    "\n",
    "Here we perform [logistic regression](http://ufldl.stanford.edu/tutorial/supervised/LogisticRegression/) on each class of digit. For a given digit, then we choose the class with maximum (log) likelihood that the digit belongs to that class. We use stochastic gradient descent to get the values of the regression parameters. \n",
    "\n",
    "Note here that these likelihoods are not probabilities that the digit belongs to a particular class (they need not even sum to 1). This is a discriminative algorithm.\n",
    "\n",
    "The naive implementation of this algorithm is unlikely to give a very good result, as for each class the ratio of members of the class to non-members of the class is 1 : 9 (ie, the data is biased). Therefore, we correct for the bias in the data by taking a 1 : 1 ratio of class members and non-class members during gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_268/915958806.py:22: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-np.dot(params[digit], vector)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.54%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train_r = np.zeros((x_train.shape[0], 1 + x_train.shape[1]*x_train.shape[2]))\n",
    "\n",
    "mean = np.mean(x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]), axis=0)\n",
    "std_dev = np.std(x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]), axis=0)\n",
    "\n",
    "for i in range(std_dev.shape[0]):\n",
    "    if np.isclose(std_dev[i], 0):\n",
    "        std_dev[i] = 1 # if STD DEV is close to 0, x - mean will already be close to 0, so we don't normalize\n",
    "\n",
    "for i in range(x_train_r.shape[0]):\n",
    "    x_train_r[i] = np.insert((np.reshape(x_train[i], (x_train.shape[1]*x_train.shape[2], )) - mean)/std_dev, 0, 1)\n",
    "\n",
    "params = np.zeros((10, x_train_r.shape[1]))\n",
    "\n",
    "def hypothesis(digit, vector):\n",
    "    return 1/(1 + np.exp(-np.dot(params[digit], vector)))\n",
    "\n",
    "# Correct for bias in data\n",
    "num_to_list = {}\n",
    "for i in range(10):\n",
    "    num_to_list[i] = []\n",
    "\n",
    "for i in range(x_train_r.shape[0]):\n",
    "    num_to_list[y_train[i]].append(i)\n",
    "\n",
    "for i in range(10):\n",
    "    num_to_list[i] = np.array(num_to_list[i])\n",
    "\n",
    "# Our hyperparameters\n",
    "NUM_ITER = 6000\n",
    "LEARN_RATE = 1e-2\n",
    "BATCH_SIZE = 360\n",
    "\n",
    "def grad_descent(digit, iterations = NUM_ITER, learning_rate = LEARN_RATE):\n",
    "    for _ in range(iterations):\n",
    "        sum = np.zeros(x_train_r.shape[1])\n",
    "        batch = np.concatenate(tuple([np.random.choice(num_to_list[p], int(BATCH_SIZE/2)) if p == digit else np.random.choice(num_to_list[p], int(BATCH_SIZE/18)) for p in range(10)]))\n",
    "\n",
    "        for i in batch:\n",
    "            if y_train[i] == digit:\n",
    "                sum += (1 - hypothesis(digit, x_train_r[i]))*x_train_r[i]\n",
    "            else:\n",
    "                sum -= hypothesis(digit, x_train_r[i])*x_train_r[i]\n",
    "        params[digit] += learning_rate*sum\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    grad_descent(i)\n",
    "\n",
    "def prediction(digit):\n",
    "    r_dig = np.insert((np.reshape(digit, (x_train.shape[1]*x_train.shape[2], )) - mean)/std_dev, 0, 1)\n",
    "    return np.argmax([hypothesis(i, r_dig) for i in range(10)])\n",
    "\n",
    "num_occ = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    if prediction(x_test[i]) == y_test[i]:\n",
    "        num_occ += 1\n",
    "\n",
    "print(f'Accuracy: {num_occ*100/x_test.shape[0]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 4\n",
      "Actual: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7009/3849353442.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-np.dot(params[digit], vector)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, x_test.shape[0])\n",
    "plt.imshow(x_test[i]);\n",
    "print(f'Predicted: {prediction(x_test[i])}')\n",
    "print(f'Actual: {y_test[i]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ```6000``` iterations of gradient descent, a learning rate of ```0.01``` and a minibatch size of ```180```, we get an accuracy of ```88.54%```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Softmax Regression\n",
    "\n",
    "[This](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/) is more appropriate for multiclass classification than plain logistic regression. Here the probabilities of a digit belonging to a class are drawn from a multivariate Bernoulli distribution, on which we perform maximum likelihood estimation via stochastic gradient descent. \n",
    "\n",
    "This is also a discriminative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_268/615135398.py:32: RuntimeWarning: overflow encountered in exp\n",
      "  sum += np.exp(arr[j] - arr[i])\n",
      "/tmp/ipykernel_268/615135398.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  sum = np.exp(-arr[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.13%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train_r = np.zeros((x_train.shape[0], 1 + x_train.shape[1]*x_train.shape[2]))\n",
    "\n",
    "mean = np.mean(x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]), axis=0)\n",
    "std_dev = np.std(x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]), axis=0)\n",
    "\n",
    "for i in range(std_dev.shape[0]):\n",
    "    if np.isclose(std_dev[i], 0):\n",
    "        std_dev[i] = 1 # if STD DEV is close to 0, x - mean will already be close to 0, so we don't normalize\n",
    "\n",
    "for i in range(x_train_r.shape[0]):\n",
    "    x_train_r[i] = np.insert((np.reshape(x_train[i], (x_train.shape[1]*x_train.shape[2], )) - mean)/std_dev, 0, 1)\n",
    "\n",
    "params = np.zeros((x_train_r.shape[1], 9))\n",
    "\n",
    "def sstat(digit):\n",
    "    arr = np.zeros(9)\n",
    "    if digit < 9:\n",
    "        arr[digit] = 1\n",
    "    return arr\n",
    "\n",
    "def hypothesis(vector):\n",
    "    arr = np.matmul(np.transpose(params), vector)\n",
    "    narr = np.zeros(9)\n",
    "    for i in range(9):\n",
    "        sum = np.exp(-arr[i])\n",
    "        for j in range(9):\n",
    "            sum += np.exp(arr[j] - arr[i])\n",
    "        narr[i] = 1/sum\n",
    "    return narr\n",
    "\n",
    "# Our hyperparameters for gradient descent\n",
    "NUM_ITER = 8000\n",
    "LEARN_RATE = 1e-2\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "for _ in range(NUM_ITER):\n",
    "    sum = np.zeros((x_train_r.shape[1], 9))\n",
    "    batch = np.random.choice(range(x_train_r.shape[0]), BATCH_SIZE)\n",
    "    for i in batch:\n",
    "        sum += np.outer(x_train_r[i], sstat(y_train[i]) - hypothesis(x_train_r[i]))\n",
    "    params += LEARN_RATE*sum\n",
    "\n",
    "def prediction(img):\n",
    "    dig = np.insert((img.reshape(x_train.shape[1]*x_train.shape[2]) - mean)/std_dev, 0, 1)\n",
    "    hyp = hypothesis(dig)\n",
    "    hyp = np.append(hyp, 1 - np.sum(hyp))\n",
    "    return np.argmax(hyp)\n",
    "\n",
    "num_occ = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    if prediction(x_test[i]) == y_test[i]:\n",
    "        num_occ += 1\n",
    "\n",
    "print(f'Accuracy: {num_occ*100/x_test.shape[0]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 3\n",
      "Actual: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_268/3308815789.py:23: RuntimeWarning: overflow encountered in exp\n",
      "  sum = np.exp(-arr[i])\n",
      "/tmp/ipykernel_268/3308815789.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  sum += np.exp(arr[j] - arr[i])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, x_test.shape[0])\n",
    "plt.imshow(x_test[i]);\n",
    "print(f'Predicted: {prediction(x_test[i])}')\n",
    "print(f'Actual: {y_test[i]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ```8000``` iterations of gradient descent, a learning rate of ```0.01``` and a minibatch size of ```500```, we get an accuracy of ```90.13%```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Discriminant Analysis\n",
    "\n",
    "We assume each class of digit is distributed according to some Multivariate Gaussian whose mean and covariance we calculate (using the sample mean and sample covariance of each digit). Have a look at the slides on Multivariate Gaussian for an overview.\n",
    "\n",
    "To classify a digit then, we choose the class such that the probability that the digit belongs to the class is maximum. We calculate this probability using Baye's Theorem ( $P(y | x) = \\frac{P(x | y)P(y)}{P(x)}$ ). This is an example of a generative learning model.\n",
    "\n",
    "However, while calculating the sample covariance, it will come out to be singular or almost singular, as there are a large number of principal components with eigenvalues close to 0 (or 0). Therefore, we must reduce the dimensionality of the data by projecting it onto the space spanned by the first few principal components. Note that since we're already calculating the principal components here, there is no need to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.59%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NUM_PRINC = 150 # Number of Principal Components (our hyperparameter)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train_r = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]).astype('float64')\n",
    "\n",
    "num_to_list = {}\n",
    "\n",
    "for i in range(10):\n",
    "    num_to_list[i] = []\n",
    "\n",
    "for i in range(x_train_r.shape[0]):\n",
    "    num_to_list[y_train[i]].append(x_train_r[i])\n",
    "\n",
    "for i in range(10):\n",
    "    num_to_list[i] = np.array(num_to_list[i])\n",
    "\n",
    "means = np.array([np.mean(num_to_list[i], axis=0) for i in range(10)])\n",
    "covariances = np.array([np.cov(num_to_list[i].T, bias=True) for i in range(10)])\n",
    "\n",
    "princ_comps = np.zeros((10, NUM_PRINC, x_train_r.shape[1]))\n",
    "eigen_vals = np.zeros((10, NUM_PRINC))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = np.linalg.eigh(covariances[i])\n",
    "    eigen_vals[i] = x[x.size - NUM_PRINC:][::-1]\n",
    "    for j in range(NUM_PRINC):\n",
    "        princ_comps[i][j] = y[: , y.shape[1] - j - 1]\n",
    "\n",
    "def projection(num, vector):\n",
    "    return np.array([np.dot(x, vector) for x in princ_comps[num]])\n",
    "\n",
    "log_determinants = np.array([np.sum(np.log(eigen_vals[i])) for i in range(10)])\n",
    "proj_means = np.array([projection(i, means[i]) for i in range(10)])\n",
    "\n",
    "\n",
    "def neg_log_prob(num, vector):\n",
    "    wrt_mean = projection(num, vector) - proj_means[num]\n",
    "    return log_determinants[num] + np.sum([(wrt_mean[i] ** 2)/eigen_vals[num][i] for i in range(NUM_PRINC)]) + np.log(x_train_r.shape[0]/num_to_list[num].shape[0])\n",
    "\n",
    "def prediction(digit):\n",
    "    digit = digit.reshape(x_train_r.shape[1]).astype('float64')\n",
    "    return np.argmin(np.array([neg_log_prob(i, digit) for i in range(10)]))\n",
    "\n",
    "num_occ = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    if prediction(x_test[i]) == y_test[i]:\n",
    "        num_occ += 1\n",
    "\n",
    "print(f'Accuracy: {num_occ*100/x_test.shape[0]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 6\n",
      "Actual: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAasklEQVR4nO3db2yV9f3/8dfh3xG0PayU9vSM0hVQUIGaMSgN2uFoKF1C+HcD1EUwBL6wYgbMaVgUZFvSDRM1mg52Y4ORCDgSC5F8x4LFtl9dywJCCHFraNPxJ6VlknBOKVIq/fxu8PPMAy14Duf03VOej+RK6DnXp+ft5SVPL87phcc55wQAQC8bYD0AAOD+RIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJQdYD3Kqrq0vNzc1KSUmRx+OxHgcAECXnnNra2hQIBDRgQM/XOX0uQM3NzcrOzrYeAwBwj86dO6dRo0b1+HyfC1BKSook6Un9WIM02HgaAEC0vlKnPtH/hn8/70nCAlReXq433nhDLS0tysvL07vvvqtp06bddd3Xf+w2SIM1yEOAACDp/P87jN7tbZSEfAjh/fff1/r167Vp0yZ99tlnysvLU3FxsS5evJiIlwMAJKGEBOjNN9/UihUr9MILL+ixxx7Ttm3bNGzYMP3pT39KxMsBAJJQ3AN0/fp1HTt2TEVFRf99kQEDVFRUpNra2tv27+joUCgUitgAAP1f3AP0xRdf6MaNG8rMzIx4PDMzUy0tLbftX1ZWJp/PF974BBwA3B/MfxB1w4YNCgaD4e3cuXPWIwEAekHcPwWXnp6ugQMHqrW1NeLx1tZW+f3+2/b3er3yer3xHgMA0MfF/QpoyJAhmjJliiorK8OPdXV1qbKyUgUFBfF+OQBAkkrIzwGtX79eS5cu1Q9+8ANNmzZNb7/9ttrb2/XCCy8k4uUAAEkoIQFavHix/vOf/2jjxo1qaWnRE088oYMHD972wQQAwP3L45xz1kN8UygUks/n00zN404IAJCEvnKdqtJ+BYNBpaam9rif+afgAAD3JwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAxyHoAAN9Ow1vTo17TuHhbAibp3vNnCqNe01oQSsAkSBZcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKWDg6oL8qNf05o1FY7Ezpyb6Rc3RLykOPBH9IvRJXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSlwjzJrU6NeszPnDwmYJPk8f6YwhlWhuM8BG1wBAQBMECAAgIm4B+j111+Xx+OJ2CZMmBDvlwEAJLmEvAf0+OOP66OPPvrviwzirSYAQKSElGHQoEHy+/2J+NYAgH4iIe8BnT59WoFAQGPGjNFzzz2ns2fP9rhvR0eHQqFQxAYA6P/iHqD8/Hzt2LFDBw8e1NatW9XU1KSnnnpKbW1t3e5fVlYmn88X3rKzs+M9EgCgD/I451wiX+Dy5cvKycnRm2++qeXLl9/2fEdHhzo6OsJfh0IhZWdna6bmaZBncCJHA+Iitp8DqknAJMknlp8Dai3gT0n6uq9cp6q0X8FgUKmpPf/3kfBPBwwfPlyPPPKIGhoaun3e6/XK6/UmegwAQB+T8J8DunLlihobG5WVlZXolwIAJJG4B+ill15SdXW1/v3vf+vvf/+7FixYoIEDB+qZZ56J90sBAJJY3P8I7vz583rmmWd06dIljRw5Uk8++aTq6uo0cuTIeL8UACCJxT1Ae/bsife3BHpNw1vTo17zt5xtCZgk+fCBAkSLe8EBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYS/hfSARZi+VtKJW4s+jVuLIrewBUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATHA3bPRLO3NqrEeIu1juUP1p3WMxvda4dXUxrQOiwRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5GiV11dkB/1mtyX/5mASWyNfX9V1GtiuUHoOHFTUfRdXAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GSl6VSw3Ft2ZU5OASeKnt24sCvQ3XAEBAEwQIACAiagDVFNTo7lz5yoQCMjj8Wjfvn0RzzvntHHjRmVlZWno0KEqKirS6dOn4zUvAKCfiDpA7e3tysvLU3l5ebfPb9myRe+88462bdumI0eO6MEHH1RxcbGuXbt2z8MCAPqPqD+EUFJSopKSkm6fc87p7bff1quvvqp58+ZJknbu3KnMzEzt27dPS5YsubdpAQD9RlzfA2pqalJLS4uKiorCj/l8PuXn56u2trbbNR0dHQqFQhEbAKD/i2uAWlpaJEmZmZkRj2dmZoafu1VZWZl8Pl94y87OjudIAIA+yvxTcBs2bFAwGAxv586dsx4JANAL4hogv98vSWptbY14vLW1Nfzcrbxer1JTUyM2AED/F9cA5ebmyu/3q7KyMvxYKBTSkSNHVFBQEM+XAgAkuag/BXflyhU1NDSEv25qatKJEyeUlpam0aNHa+3atfrNb36jhx9+WLm5uXrttdcUCAQ0f/78eM4NAEhyUQfo6NGjevrpp8Nfr1+/XpK0dOlS7dixQy+//LLa29u1cuVKXb58WU8++aQOHjyoBx54IH5TAwCSnsc556yH+KZQKCSfz6eZmqdBnsHW4+AOri7Ij3rN/5X/IQGT2IrlZqR9XaAm+t8WhlUcScAkSEZfuU5Vab+CweAd39c3/xQcAOD+RIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNR/3UMACI1Lt5mPUL8LY5hTXncp+hWLHcfH7euLgGT4F5xBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpIjZ/5X/wXoE3Idiufnr89MLY3qtpi2PRr1mWMWRmF7rfsQVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAuj3dubUxLawPPp1xRVPxPZa9yGugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFGp4a3qMK0/Ec4yk9fyZwqjXfFr3WAImud24dXUxrbu6ID/qNc2FnqjXzJj+edRrYr6xKPocroAAACYIEADARNQBqqmp0dy5cxUIBOTxeLRv376I55ctWyaPxxOxzZkzJ17zAgD6iagD1N7erry8PJWXl/e4z5w5c3ThwoXwtnv37nsaEgDQ/0T9IYSSkhKVlJTccR+v1yu/3x/zUACA/i8h7wFVVVUpIyND48eP1+rVq3Xp0qUe9+3o6FAoFIrYAAD9X9wDNGfOHO3cuVOVlZX63e9+p+rqapWUlOjGjRvd7l9WViafzxfesrOz4z0SAKAPivvPAS1ZsiT860mTJmny5MkaO3asqqqqNGvWrNv237Bhg9avXx/+OhQKESEAuA8k/GPYY8aMUXp6uhoaGrp93uv1KjU1NWIDAPR/CQ/Q+fPndenSJWVlZSX6pQAASSTqP4K7cuVKxNVMU1OTTpw4obS0NKWlpWnz5s1atGiR/H6/Ghsb9fLLL2vcuHEqLi6O6+AAgOQWdYCOHj2qp59+Ovz11+/fLF26VFu3btXJkyf15z//WZcvX1YgENDs2bP161//Wl6vN35TAwCSXtQBmjlzppxzPT7/t7/97Z4GAiw9Vfo/Ua8ZVnEk6jXjFNtNQntLTP9MFdG/Tmv0S6TmWBahL+JecAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAR97+SG8lnxvTPrUfoM5oLPVGvieUu0Lip4a3pMaw6Ee8xevT8mcIYVoXiPkd/xRUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCm5FCn9Y9FtvCnJr4DtIHNC7eFvWa56dHf8PKmI95HxbLsevNG4vGIpZ/T+NUl4BJ+ieugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFArUuNgWLo7vHMlqZyw3Ze2HN3Ltj2L+bwPfCldAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJbkYKDas4EtO64oonol6TWZsa9ZqYbvYJfMPzZwqtR0A3uAICAJggQAAAE1EFqKysTFOnTlVKSooyMjI0f/581dfXR+xz7do1lZaWasSIEXrooYe0aNEitba2xnVoAEDyiypA1dXVKi0tVV1dnQ4dOqTOzk7Nnj1b7e3t4X3WrVunDz/8UHv37lV1dbWam5u1cOHCuA8OAEhuUX0I4eDBgxFf79ixQxkZGTp27JgKCwsVDAb1xz/+Ubt27dKPfvQjSdL27dv16KOPqq6uTtOnT4/f5ACApHZP7wEFg0FJUlpamiTp2LFj6uzsVFFRUXifCRMmaPTo0aqtre32e3R0dCgUCkVsAID+L+YAdXV1ae3atZoxY4YmTpwoSWppadGQIUM0fPjwiH0zMzPV0tLS7fcpKyuTz+cLb9nZ2bGOBABIIjEHqLS0VKdOndKePXvuaYANGzYoGAyGt3Pnzt3T9wMAJIeYfhB1zZo1OnDggGpqajRq1Kjw436/X9evX9fly5cjroJaW1vl9/u7/V5er1derzeWMQAASSyqKyDnnNasWaOKigodPnxYubm5Ec9PmTJFgwcPVmVlZfix+vp6nT17VgUFBfGZGADQL0R1BVRaWqpdu3Zp//79SklJCb+v4/P5NHToUPl8Pi1fvlzr169XWlqaUlNT9eKLL6qgoIBPwAEAIkQVoK1bt0qSZs6cGfH49u3btWzZMknSW2+9pQEDBmjRokXq6OhQcXGxfv/738dlWABA/+FxzjnrIb4pFArJ5/NppuZpkGew9TjoAxreiv7quXHxtgRMgr5g7Purol4zbl1dAiZBT75ynarSfgWDQaWm9nwDYu4FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcDRv4hqsL8qNe01zoScAkt+vNO3w/f6Yw6jVNWx6Nes2wiiNRr0Hfx92wAQB9GgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAgDiipuRAgD6NAIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEVAEqKyvT1KlTlZKSooyMDM2fP1/19fUR+8ycOVMejydiW7VqVVyHBgAkv6gCVF1drdLSUtXV1enQoUPq7OzU7Nmz1d7eHrHfihUrdOHChfC2ZcuWuA4NAEh+g6LZ+eDBgxFf79ixQxkZGTp27JgKCwvDjw8bNkx+vz8+EwIA+qV7eg8oGAxKktLS0iIef++995Senq6JEydqw4YNunr1ao/fo6OjQ6FQKGIDAPR/UV0BfVNXV5fWrl2rGTNmaOLEieHHn332WeXk5CgQCOjkyZN65ZVXVF9frw8++KDb71NWVqbNmzfHOgYAIEl5nHMuloWrV6/WX//6V33yyScaNWpUj/sdPnxYs2bNUkNDg8aOHXvb8x0dHero6Ah/HQqFlJ2drZmap0GewbGMBgAw9JXrVJX2KxgMKjU1tcf9YroCWrNmjQ4cOKCampo7xkeS8vPzJanHAHm9Xnm93ljGAAAksagC5JzTiy++qIqKClVVVSk3N/eua06cOCFJysrKimlAAED/FFWASktLtWvXLu3fv18pKSlqaWmRJPl8Pg0dOlSNjY3atWuXfvzjH2vEiBE6efKk1q1bp8LCQk2ePDkh/wAAgOQU1XtAHo+n28e3b9+uZcuW6dy5c/rJT36iU6dOqb29XdnZ2VqwYIFeffXVO/454DeFQiH5fD7eAwKAJJWQ94Du1qrs7GxVV1dH8y0BAPcp7gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADAxyHqAWznnJElfqVNyxsMAAKL2lTol/ff38570uQC1tbVJkj7R/xpPAgC4F21tbfL5fD0+73F3S1Qv6+rqUnNzs1JSUuTxeCKeC4VCys7O1rlz55Sammo0oT2Ow00ch5s4DjdxHG7qC8fBOae2tjYFAgENGNDzOz197gpowIABGjVq1B33SU1Nva9PsK9xHG7iONzEcbiJ43CT9XG405XP1/gQAgDABAECAJhIqgB5vV5t2rRJXq/XehRTHIebOA43cRxu4jjclEzHoc99CAEAcH9IqisgAED/QYAAACYIEADABAECAJhImgCVl5fre9/7nh544AHl5+frH//4h/VIve7111+Xx+OJ2CZMmGA9VsLV1NRo7ty5CgQC8ng82rdvX8Tzzjlt3LhRWVlZGjp0qIqKinT69GmbYRPobsdh2bJlt50fc+bMsRk2QcrKyjR16lSlpKQoIyND8+fPV319fcQ+165dU2lpqUaMGKGHHnpIixYtUmtrq9HEifFtjsPMmTNvOx9WrVplNHH3kiJA77//vtavX69Nmzbps88+U15enoqLi3Xx4kXr0Xrd448/rgsXLoS3Tz75xHqkhGtvb1deXp7Ky8u7fX7Lli165513tG3bNh05ckQPPvigiouLde3atV6eNLHudhwkac6cORHnx+7du3txwsSrrq5WaWmp6urqdOjQIXV2dmr27Nlqb28P77Nu3Tp9+OGH2rt3r6qrq9Xc3KyFCxcaTh1/3+Y4SNKKFSsizoctW7YYTdwDlwSmTZvmSktLw1/fuHHDBQIBV1ZWZjhV79u0aZPLy8uzHsOUJFdRURH+uqury/n9fvfGG2+EH7t8+bLzer1u9+7dBhP2jluPg3POLV261M2bN89kHisXL150klx1dbVz7ua/+8GDB7u9e/eG9/nnP//pJLna2lqrMRPu1uPgnHM//OEP3c9+9jO7ob6FPn8FdP36dR07dkxFRUXhxwYMGKCioiLV1tYaTmbj9OnTCgQCGjNmjJ577jmdPXvWeiRTTU1NamlpiTg/fD6f8vPz78vzo6qqShkZGRo/frxWr16tS5cuWY+UUMFgUJKUlpYmSTp27Jg6OzsjzocJEyZo9OjR/fp8uPU4fO29995Tenq6Jk6cqA0bNujq1asW4/Woz92M9FZffPGFbty4oczMzIjHMzMz9a9//ctoKhv5+fnasWOHxo8frwsXLmjz5s166qmndOrUKaWkpFiPZ6KlpUWSuj0/vn7ufjFnzhwtXLhQubm5amxs1C9/+UuVlJSotrZWAwcOtB4v7rq6urR27VrNmDFDEydOlHTzfBgyZIiGDx8esW9/Ph+6Ow6S9OyzzyonJ0eBQEAnT57UK6+8ovr6en3wwQeG00bq8wHCf5WUlIR/PXnyZOXn5ysnJ0d/+ctftHz5csPJ0BcsWbIk/OtJkyZp8uTJGjt2rKqqqjRr1izDyRKjtLRUp06dui/eB72Tno7DypUrw7+eNGmSsrKyNGvWLDU2Nmrs2LG9PWa3+vwfwaWnp2vgwIG3fYqltbVVfr/faKq+Yfjw4XrkkUfU0NBgPYqZr88Bzo/bjRkzRunp6f3y/FizZo0OHDigjz/+OOKvb/H7/bp+/bouX74csX9/PR96Og7dyc/Pl6Q+dT70+QANGTJEU6ZMUWVlZfixrq4uVVZWqqCgwHAye1euXFFjY6OysrKsRzGTm5srv98fcX6EQiEdOXLkvj8/zp8/r0uXLvWr88M5pzVr1qiiokKHDx9Wbm5uxPNTpkzR4MGDI86H+vp6nT17tl+dD3c7Dt05ceKEJPWt88H6UxDfxp49e5zX63U7duxwn3/+uVu5cqUbPny4a2lpsR6tV/385z93VVVVrqmpyX366aeuqKjIpaenu4sXL1qPllBtbW3u+PHj7vjx406Se/PNN93x48fdmTNnnHPO/fa3v3XDhw93+/fvdydPnnTz5s1zubm57ssvvzSePL7udBza2trcSy+95Gpra11TU5P76KOP3Pe//3338MMPu2vXrlmPHjerV692Pp/PVVVVuQsXLoS3q1evhvdZtWqVGz16tDt8+LA7evSoKygocAUFBYZTx9/djkNDQ4P71a9+5Y4ePeqamprc/v373ZgxY1xhYaHx5JGSIkDOOffuu++60aNHuyFDhrhp06a5uro665F63eLFi11WVpYbMmSI++53v+sWL17sGhoarMdKuI8//thJum1bunSpc+7mR7Ffe+01l5mZ6bxer5s1a5arr6+3HToB7nQcrl696mbPnu1GjhzpBg8e7HJyctyKFSv63f+kdffPL8lt3749vM+XX37pfvrTn7rvfOc7btiwYW7BggXuwoULdkMnwN2Ow9mzZ11hYaFLS0tzXq/XjRs3zv3iF79wwWDQdvBb8NcxAABM9Pn3gAAA/RMBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYOL/AbMzmfp2EtcdAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0, x_test.shape[0])\n",
    "plt.imshow(x_test[i]);\n",
    "print(f'Predicted: {prediction(x_test[i])}')\n",
    "print(f'Actual: {y_test[i]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "The hyperparameter here is the number of principal components considered. We choose the number that maximizes the accuracy on testing.\n",
    "\n",
    "| Number of Principal Components           | Accuracy               |\n",
    "| ---------------------------------------- | -----------------------|\n",
    "| ```1```                                  | ```4.55%```            |\n",
    "| ```80```                                 | ```94.24%```           |\n",
    "| ```150```                                | ```95.59%```           |\n",
    "| ```240```                                | ```94.78%```           |\n",
    "| ```320```                                | ```93.72%```           |\n",
    "| ```400```                                | ```91.45%```           |\n",
    "| ```480```                                | ```87.61%```           |\n",
    "| ```560```                                | ```65.83%```           |\n",
    "| ```640```                                | ```9.8%```             |\n",
    "| ```720```                                | ```9.8%```             |\n",
    "| ```784```                                | ```9.8%```             |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Support Vector Machines\n",
    "\n",
    "Here we make ${10\\choose 2} = 45$ support vector machines that can distinguish every pair of classes. We will use Linear and RBF/Gaussian Kernels for the support vector machines and use the [SMO Algorithm](https://web.iitd.ac.in/~sumeet/tr-98-14.pdf), discovered by John C Platt for optimization. This is much faster than Gradient Descent would be, as it makes use of the fact that the dual problem of the SVM is a Quadratic Optimization Problem.\n",
    "\n",
    "The support vector machine is another discriminative algorithm, but this one can identify non-linear decision boundaries as well.\n",
    "\n",
    "For a given image, we will map it to the digit to which it is classified the most (on average, the image will be mapped to the correct digit $\\frac{9}{4}$ times more than the other digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "mean = np.mean(x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]), axis=0)\n",
    "std_dev = np.std(x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]), axis=0)\n",
    "\n",
    "for i in range(std_dev.shape[0]):\n",
    "    if np.isclose(std_dev[i], 0):\n",
    "        std_dev[i] = 1 # if STD DEV is close to 0, x - mean will already be close to 0, so we don't normalize\n",
    "\n",
    "num_to_list = {}\n",
    "for i in range(10):\n",
    "    num_to_list[i] = []\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    num_to_list[y_train[i]].append((np.reshape(x_train[i], (x_train.shape[1]*x_train.shape[2], )) - mean)/std_dev)\n",
    "\n",
    "for i in range(10):\n",
    "    num_to_list[i] = np.array(num_to_list[i])\n",
    "\n",
    "# Our hyperparameters\n",
    "GAUSS_PARAM = 1e-2 # Only for the Gaussian Kernel\n",
    "SOFTEN_PARAM = 3000\n",
    "LEARN_RATE = 1e-2\n",
    "NUM_ITER = 50\n",
    "BATCH_SIZE = 5 # We adjust these many params at a time\n",
    "EPS = 1e-3\n",
    "\n",
    "def isclose(a, b, threshold_factor = 1):\n",
    "    return abs(a - b) < EPS*threshold_factor\n",
    "\n",
    "def kernel(x, y, Linear=False):\n",
    "    return np.dot(x, y) if Linear else np.exp(-GAUSS_PARAM*(np.linalg.norm(x - y)**2))\n",
    "\n",
    "svm_params = [[np.zeros(num_to_list[i].shape[0]), np.zeros(num_to_list[j].shape[0])] for i in range(10) for j in range(i + 1, 10)]\n",
    "bias = np.array([0 for i in range(10) for j in range(i + 1)])\n",
    "svm_outputs = [[np.zeros(num_to_list[i].shape[0]), np.zeros(num_to_list[j].shape[0])] for i in range(10) for j in range(i + 1, 10)]\n",
    "\n",
    "\n",
    "def get_index(i, j):\n",
    "    # assert i < j\n",
    "    return int(i*(17 - i)/2) + j - 1\n",
    "\n",
    "\n",
    "def two_opt(i, j, ind1, ind2, y1, y2):\n",
    "    # assert i < j, ind1 != ind2\n",
    "    numi = num_to_list[i].shape[0]\n",
    "    numj = num_to_list[j].shape[0]\n",
    "    C = SOFTEN_PARAM/(numi + numj)\n",
    "    alph1 = svm_params[get_index(i, j)][0 if y1 == 1 else 1][ind1]\n",
    "    alph2 = svm_params[get_index(i, j)][0 if y2 == 1 else 1][ind2]\n",
    "    L = max(0, alph2 - alph1) if y1 != y2 else max(0, alph1 + alph2 - C) # Lower limit on alph2\n",
    "    H = min(C, C + alph2 - alph1) if y1 != y2 else min(C, alph2 + alph1) # Upper limit on alph2\n",
    "    if isclose(L, H):\n",
    "        return\n",
    "    # We explicitly set alph1 and alph2 to optimal values without changing other parameters\n",
    "    x1 = num_to_list[i if y1 == 1 else j][ind1]\n",
    "    x2 = num_to_list[i if y2 == 1 else j][ind2]\n",
    "    kx1 = kernel(x1, x1)\n",
    "    kx2 = kernel(x2, x2)\n",
    "    kx1x2 = kernel(x1, x2)\n",
    "    eta = kx1 + kx2 - 2*kx1x2\n",
    "    u1 = svm_outputs[get_index(i, j)][0 if y1 == 1 else 1][ind1]\n",
    "    u2 = svm_outputs[get_index(i, j)][0 if y2 == 1 else 1][ind2]\n",
    "    poss_alph2 = alph2 + y2*(u1 - u2 + y2 - y1)/eta\n",
    "    old_alph2 = alph2\n",
    "    if poss_alph2 <= L:\n",
    "        alph2 = L\n",
    "    elif poss_alph2 >= H:\n",
    "        alph2 = H\n",
    "    else:\n",
    "        alph2 = poss_alph2\n",
    "    if isclose(alph2, old_alph2, alph2 + old_alph2):\n",
    "        return\n",
    "\n",
    "    old_alph1 = alph1\n",
    "    alph1 += y1*y2(alph2 - old_alph2)\n",
    "    b1 = -(u1 - y1 + y1*(alph1 - old_alph1)*kx1 + y2*(alph2 - old_alph2)*kx1x2) + bias[get_index(i, j)]\n",
    "    b2 = -(u2 - y2 + y1*(alph1 - old_alph1)*kx1x2 + y2*(alph2 - old_alph2)*kx2) + bias[get_index(i, j)]\n",
    "    if (isclose(0, alph1) or isclose(C, alph1)) == (isclose(0, alph2) or isclose(C, alph2)):\n",
    "        bias[get_index(i, j)] = (b1 + b2)/2\n",
    "    else:\n",
    "        if alph1 > 0 and alph1 < C:\n",
    "            bias[get_index(i, j)] = b1\n",
    "        else:\n",
    "            bias[get_index(i, j)] = b2\n",
    "\n",
    "    svm_params[get_index(i, j)][0 if y1 == 1 else 1][ind1] = alph1\n",
    "    svm_params[get_index(i, j)][0 if y2 == 1 else 1][ind2] = alph2\n",
    "\n",
    "    for k in range(numi):\n",
    "        svm_outputs[get_index(i, j)][0][k] = np.sum([svm_params[get_index(i, j)][0][l]*kernel(num_to_list[i][l], num_to_list[i][k]) for l in range(numi)]) - np.sum([svm_params[get_index(i, j)][1][l]*kernel(num_to_list[j][l], num_to_list[i][k]) for l in range(numj)]) + bias[get_index(i, j)]\n",
    "    \n",
    "    for k in range(numj):\n",
    "        svm_outputs[get_index(i, j)][1][k] = np.sum([svm_params[get_index(i, j)][0][l]*kernel(num_to_list[i][l], num_to_list[j][k]) for l in range(numi)]) - np.sum([svm_params[get_index(i, j)][1][l]*kernel(num_to_list[j][l], num_to_list[j][k]) for l in range(numj)]) + bias[get_index(i, j)]\n",
    "\n",
    "def KKT_violate(i, j, ind, y):\n",
    "    func_marg = y*svm_outputs[get_index(i, j)][0 if y == 1 else 1][ind]\n",
    "    alpha = svm_params[get_index(i, j)][0 if y == 1 else 1][ind]\n",
    "    C = SOFTEN_PARAM/(num_to_list[i].shape[0] + num_to_list[j].shape[0])\n",
    "    ans = (isclose(alpha, 0) != (func_marg > 1 + EPS)) or ((EPS < alpha and alpha < C - EPS) != isclose(func_marg, 1)) or (isclose(alpha, C) != (func_marg < 1 - EPS))\n",
    "    return ans\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(i + 1, 10):\n",
    "        while True:\n",
    "            numi = num_to_list[i].shape[0]\n",
    "            numj = num_to_list[j].shape[0]\n",
    "\n",
    "            ind1 = -1\n",
    "            y1 = 0\n",
    "            for k in range(numi):\n",
    "                if KKT_violate(i, j, k, 1):\n",
    "                    ind1 = k\n",
    "                    y1 = 1\n",
    "                    break\n",
    "            if ind1 == -1:\n",
    "                for k in range(numj):\n",
    "                    if KKT_violate(i, j, k, -1):\n",
    "                        ind1 = k\n",
    "                        y1 = -1\n",
    "                        break\n",
    "        \n",
    "            if ind1 == -1:\n",
    "                break\n",
    "\n",
    "            ind2 = -1\n",
    "            y2 = 0\n",
    "            for k in range(numi):\n",
    "                if KKT_violate(i, j, k, 1) and not (k == ind1 and y1 == 1):\n",
    "                    ind2 = k\n",
    "                    y2 = 1\n",
    "                    break\n",
    "            if ind2 == -1:\n",
    "                for k in range(numj):\n",
    "                    if KKT_violate(i, j, k, -1) and not (k == ind2 and y2 == -1):\n",
    "                        ind2 = k\n",
    "                        y2 = -1\n",
    "                        break\n",
    "            \n",
    "            if ind2 == -1:\n",
    "                y2 = np.random.choice([-1, 1])\n",
    "                if y2 == 1:\n",
    "                    ind2 = np.random.randint(0, numi)\n",
    "                else:\n",
    "                    ind2 = np.random.randint(0, numj)\n",
    "            \n",
    "            two_opt(i, j, ind1, ind2, y1, y2)\n",
    "        \n",
    "\n",
    "\n",
    "def hypothesis(i, j, vector):\n",
    "    return 1 if np.sum([svm_params[get_index(i, j)][0][k]*kernel(num_to_list[i][k], vector) for k in range(num_to_list[i].shape[0])]) - np.sum([svm_params[get_index(i, j)][1][k]*kernel(num_to_list[j][k], vector) for k in range(num_to_list[j].shape[0])]) + bias[get_index(i, j)] >= 0 else -1\n",
    "\n",
    "def prediction(img):\n",
    "    rimg = img.reshape(x_train.shape[1]*x_train.shape[2])\n",
    "    counts = np.zeros(10, dtype=int)\n",
    "    for i in range(10):\n",
    "        for j in range(i + 1, 10):\n",
    "            if hypothesis(i, j, rimg) == 1:\n",
    "                counts[i] += 1\n",
    "            else:\n",
    "                counts[j] += 1\n",
    "    return np.argmax(counts)\n",
    "\n",
    "num_occ = 0\n",
    "for i in range(x_test.shape[0]):\n",
    "    if prediction(x_test[i]) == y_test[i]:\n",
    "        num_occ += 1\n",
    "\n",
    "print(f'Accuracy: {num_occ*100/x_test.shape[0]}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, x_test.shape[0])\n",
    "plt.imshow(x_test[i]);\n",
    "print(f'Predicted: {prediction(x_test[i])}')\n",
    "print(f'Actual: {y_test[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
